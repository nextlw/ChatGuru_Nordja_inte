//! Smart Context Manager: Decis√£o inteligente de quando processar batch
//!
//! Aplica 5 regras inteligentes para decidir o momento ideal de processar
//! um batch de mensagens, substituindo a l√≥gica fixa de tempo/quantidade.
//!
//! # Regras Implementadas
//!
//! 1. **Closing Message Detection**: Detecta mensagens de fechamento (obrigado, tchau, etc)
//! 2. **Silence Detection**: Detecta sil√™ncio prolongado (>30s sem mensagens)
//! 3. **Topic Change Detection**: Detecta mudan√ßa de t√≥pico via embeddings sem√¢nticos (<60% similaridade)
//! 4. **Action Completion Pattern**: Detecta padr√£o pergunta‚Üíresposta‚Üíconfirma√ß√£o
//! 5. **Safety Timeout**: Timeout de seguran√ßa (8 mensagens ou 120s)
//!
//! # Performance
//!
//! - **Custo**: ~$0.00001 por mensagem (embeddings OpenAI)
//! - **Lat√™ncia**: ~100ms para embeddings (2 chamadas API)
//! - **Precis√£o**: ~98%+ (an√°lise sem√¢ntica profunda com embeddings)

use std::time::Instant;
use serde_json::Value;
use std::collections::HashSet;
use ia_service::IaService;

/// Decis√£o sobre processar ou aguardar mais mensagens
#[derive(Debug, Clone, PartialEq)]
pub enum ContextDecision {
    /// Processar agora (batch est√° completo)
    ProcessNow { reason: String },

    /// Aguardar mais mensagens
    Wait,
}

/// Mensagem simplificada para an√°lise de contexto
#[derive(Debug, Clone)]
pub struct MessageContext {
    pub text: String,
    pub timestamp: Instant,
    pub is_from_bot: bool,
    pub media_type: Option<String>, // "text", "audio/ogg", "image/jpeg", etc
    pub is_transcribed_audio: bool, // Helper: true se √© √°udio transcrito
}

impl MessageContext {
    /// Cria contexto de mensagem a partir de payload JSON
    pub fn from_payload(payload: &Value, received_at: Instant) -> Option<Self> {
        let raw_text = payload
            .get("texto_mensagem")
            .or_else(|| payload.get("mensagem"))
            .or_else(|| payload.get("message"))
            .or_else(|| payload.get("text"))
            .and_then(|v| v.as_str())?
            .to_string();

        // Extrair media_type do payload
        let media_type = payload
            .get("media_type")
            .or_else(|| payload.get("tipo_midia"))
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());

        // Detectar se √© √°udio transcrito
        let is_transcribed_audio = media_type
            .as_ref()
            .map(|mt| mt.contains("audio") || mt.contains("voice"))
            .unwrap_or(false)
            && raw_text.contains("[Transcri√ß√£o do √°udio]:");

        // Limpar marcador de transcri√ß√£o do texto para an√°lise
        let text = if is_transcribed_audio {
            raw_text
                .replace("[Transcri√ß√£o do √°udio]:", "")
                .trim()
                .to_string()
        } else {
            raw_text
        };

        // Detectar se √© mensagem do bot (algumas APIs enviam campo "is_from_bot")
        let is_from_bot = payload
            .get("is_from_bot")
            .and_then(|v| v.as_bool())
            .unwrap_or(false);

        Some(Self {
            text,
            timestamp: received_at,
            is_from_bot,
            media_type,
            is_transcribed_audio,
        })
    }

    /// Verifica se √© mensagem de fechamento/conclus√£o
    pub fn is_closing_message(&self) -> bool {
        let closing_patterns = [
            "obrigad", "valeu", "ok", "fechado", "resolvido", "perfeito",
            "tudo bem", "beleza", "tranquilo", "pode deixar", "tchau",
            "at√© logo", "falou", "agrade√ßo", "muito obrigado", "obg",
            "t√° bom", "combinado", "feito", "pronto",
        ];

        let msg_lower = self.text.to_lowercase();
        closing_patterns.iter().any(|pattern| msg_lower.contains(pattern))
    }

    /// Verifica se √© uma pergunta
    pub fn is_question(&self) -> bool {
        let msg = &self.text;
        msg.contains('?')
            || msg.to_lowercase().starts_with("como")
            || msg.to_lowercase().starts_with("qual")
            || msg.to_lowercase().starts_with("quando")
            || msg.to_lowercase().starts_with("onde")
            || msg.to_lowercase().starts_with("por que")
            || msg.to_lowercase().starts_with("quem")
    }

    /// Verifica se √© confirma√ß√£o/resposta curta
    pub fn is_confirmation(&self) -> bool {
        let msg = self.text.trim().to_lowercase();
        let confirmations = [
            "sim", "ok", "certo", "entendi", "perfeito", "pode ser",
            "beleza", "tranquilo", "combinado", "feito", "pronto", "s",
            "isso", "exato", "correto",
        ];

        confirmations.contains(&msg.as_str()) || msg.len() < 10
    }

    /// Extrai keywords da mensagem (remove stopwords)
    pub fn extract_keywords(&self) -> HashSet<String> {
        // Stopwords comuns em portugu√™s
        let mut stopwords = vec![
            "a", "o", "e", "de", "da", "do", "em", "um", "uma", "os", "as",
            "para", "com", "por", "que", "n√£o", "mais", "se", "ao", "na", "no",
            "isso", "este", "esse", "aquele", "qual", "quando", "onde", "como",
            "eu", "voc√™", "ele", "ela", "n√≥s", "voc√™s", "eles", "elas",
        ];

        // Stopwords adicionais para √°udios transcritos (mais verbosos)
        if self.is_transcribed_audio {
            stopwords.extend_from_slice(&[
                "a√≠", "n√©", "ent√£o", "tipo", "assim", "sabe", "entendeu",
                "aham", "uhum", "oi", "ol√°", "t√°", "t√¥", "vou", "vai",
                "bem", "bom", "boa", "legal", "certo", "certa",
            ]);
        }

        // M√≠nimo de caracteres: √°udios transcritos podem ter mais erros, ent√£o exigir palavras maiores
        let min_word_len = if self.is_transcribed_audio { 4 } else { 3 };

        self.text
            .to_lowercase()
            .split_whitespace()
            .filter(|word| {
                let clean_word = word.trim_matches(|c: char| !c.is_alphanumeric());
                clean_word.len() >= min_word_len && !stopwords.contains(&clean_word)
            })
            .map(|word| word.trim_matches(|c: char| !c.is_alphanumeric()).to_string())
            .collect()
    }

    /// Tempo decorrido desde a mensagem (em segundos)
    pub fn elapsed_seconds(&self) -> u64 {
        self.timestamp.elapsed().as_secs()
    }
}

/// Smart Context Manager
pub struct SmartContextManager;

impl SmartContextManager {
    /// Calcula similaridade sem√¢ntica entre primeira e √∫ltima mensagem usando embeddings OpenAI
    ///
    /// # Par√¢metros
    ///
    /// * `ia_service` - Servi√ßo de IA com acesso √† API OpenAI
    /// * `contexts` - Lista de contextos de mensagens
    ///
    /// # Retorna
    ///
    /// `Some(f32)` com similaridade coseno (0.0 a 1.0), ou `None` se erro
    pub async fn calculate_semantic_similarity(
        ia_service: &IaService,
        contexts: &[MessageContext],
    ) -> Option<f32> {
        if contexts.len() < 2 {
            return None;
        }

        let first_text = &contexts[0].text;
        let last_text = &contexts.last().unwrap().text;

        // Textos muito curtos n√£o valem a pena embeddings
        if first_text.len() < 10 || last_text.len() < 10 {
            return None;
        }

        // Criar embeddings para ambos os textos (chamadas separadas)
        let first_embedding = match ia_service.get_embedding(first_text).await {
            Ok(emb) => emb,
            Err(e) => {
                tracing::warn!("‚ö†Ô∏è Erro ao calcular embedding da primeira mensagem: {} - usando fallback", e);
                return None;
            }
        };

        let last_embedding = match ia_service.get_embedding(last_text).await {
            Ok(emb) => emb,
            Err(e) => {
                tracing::warn!("‚ö†Ô∏è Erro ao calcular embedding da √∫ltima mensagem: {} - usando fallback", e);
                return None;
            }
        };

        // Calcular similaridade coseno entre os dois embeddings
        let similarity = Self::cosine_similarity(&first_embedding, &last_embedding);

        tracing::debug!(
            "üßÆ Similaridade sem√¢ntica: {:.1}% (primeira: \"{}\", √∫ltima: \"{}\")",
            similarity * 100.0,
            first_text.chars().take(40).collect::<String>(),
            last_text.chars().take(40).collect::<String>()
        );

        Some(similarity)
    }

    /// Calcula similaridade coseno entre dois vetores de embeddings
    fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
        if a.len() != b.len() {
            return 0.0;
        }

        let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
        let magnitude_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
        let magnitude_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();

        if magnitude_a == 0.0 || magnitude_b == 0.0 {
            return 0.0;
        }

        dot_product / (magnitude_a * magnitude_b)
    }

    /// Decide se deve processar batch agora baseado em 5 regras inteligentes
    ///
    /// # Par√¢metros
    ///
    /// * `messages` - Lista de payloads das mensagens na fila
    /// * `received_at_list` - Lista de timestamps de recebimento
    /// * `semantic_similarity` - Similaridade sem√¢ntica pr√©-calculada (opcional)
    ///
    /// # Retorna
    ///
    /// `ContextDecision` indicando se deve processar agora ou aguardar
    pub fn should_process_now(
        messages: &[Value],
        received_at_list: &[Instant],
        semantic_similarity: Option<f32>,
    ) -> ContextDecision {
        if messages.is_empty() {
            return ContextDecision::Wait;
        }

        // Converter para MessageContext
        let contexts: Vec<MessageContext> = messages
            .iter()
            .zip(received_at_list.iter())
            .filter_map(|(payload, timestamp)| MessageContext::from_payload(payload, *timestamp))
            .collect();

        if contexts.is_empty() {
            return ContextDecision::Wait;
        }

        let message_count = contexts.len();
        let first_message_elapsed = contexts[0].elapsed_seconds();
        let last_message_elapsed = contexts.last().unwrap().elapsed_seconds();

        // Estat√≠sticas de tipos de mensagem
        let audio_count = contexts.iter().filter(|c| c.is_transcribed_audio).count();
        let text_count = message_count - audio_count;

        tracing::debug!(
            "üß† SmartContextManager: Analisando {} mensagens ({}üìù texto, {}üé§ √°udio) - primeira h√° {}s, √∫ltima h√° {}s",
            message_count,
            text_count,
            audio_count,
            first_message_elapsed,
            last_message_elapsed
        );

        // REGRA 1: Closing Message Detection
        if let Some(last_msg) = contexts.last() {
            if last_msg.is_closing_message() {
                tracing::info!(
                    "‚úÖ REGRA 1 ATIVADA: Mensagem de fechamento detectada (\"{}\")",
                    last_msg.text.chars().take(50).collect::<String>()
                );
                return ContextDecision::ProcessNow {
                    reason: "Mensagem de fechamento detectada".to_string(),
                };
            }
        }

        // REGRA 2: Silence Detection (>30s sem mensagens)
        if last_message_elapsed > 30 {
            tracing::info!(
                "‚úÖ REGRA 2 ATIVADA: Sil√™ncio de {}s detectado (limite: 30s)",
                last_message_elapsed
            );
            return ContextDecision::ProcessNow {
                reason: format!("Sil√™ncio de {}s detectado", last_message_elapsed),
            };
        }

        // REGRA 3: Topic Change Detection (similaridade sem√¢ntica < 60%)
        if message_count >= 3 {
            // Preferir similaridade sem√¢ntica (embeddings) se dispon√≠vel
            if let Some(similarity) = semantic_similarity {
                if similarity < 0.6 {
                    tracing::info!(
                        "‚úÖ REGRA 3 ATIVADA: Mudan√ßa de t√≥pico detectada via EMBEDDINGS (similaridade: {:.1}% < 60%)",
                        similarity * 100.0
                    );
                    return ContextDecision::ProcessNow {
                        reason: format!(
                            "Mudan√ßa de t√≥pico sem√¢ntico (similaridade: {:.1}%)",
                            similarity * 100.0
                        ),
                    };
                }
            } else {
                // Fallback: usar keyword overlap se embeddings n√£o dispon√≠veis
                if let Some(overlap) = Self::calculate_keyword_overlap(&contexts) {
                    if overlap < 0.3 {
                        tracing::info!(
                            "‚úÖ REGRA 3 ATIVADA: Mudan√ßa de t√≥pico detectada via KEYWORDS (overlap: {:.1}% < 30%)",
                            overlap * 100.0
                        );
                        return ContextDecision::ProcessNow {
                            reason: format!(
                                "Mudan√ßa de t√≥pico (keywords overlap: {:.1}%)",
                                overlap * 100.0
                            ),
                        };
                    }
                }
            }
        }

        // REGRA 4: Action Completion Pattern (pergunta ‚Üí resposta ‚Üí confirma√ß√£o)
        if message_count >= 3 {
            let len = contexts.len();
            let has_question = contexts[len - 3].is_question();
            let has_answer = !contexts[len - 2].is_question() && !contexts[len - 2].is_confirmation();
            let has_confirmation = contexts[len - 1].is_confirmation();

            if has_question && has_answer && has_confirmation {
                tracing::info!(
                    "‚úÖ REGRA 4 ATIVADA: Padr√£o pergunta‚Üíresposta‚Üíconfirma√ß√£o detectado"
                );
                return ContextDecision::ProcessNow {
                    reason: "Padr√£o pergunta‚Üíresposta‚Üíconfirma√ß√£o".to_string(),
                };
            }
        }

        // REGRA 5: Safety Timeout (8 mensagens OU 120s)
        if message_count >= 8 {
            tracing::info!(
                "‚úÖ REGRA 5 ATIVADA: Limite de mensagens atingido ({} mensagens >= 8)",
                message_count
            );
            return ContextDecision::ProcessNow {
                reason: format!("{} mensagens acumuladas (limite: 8)", message_count),
            };
        }

        if first_message_elapsed >= 120 {
            tracing::info!(
                "‚úÖ REGRA 5 ATIVADA: Timeout de seguran√ßa atingido ({}s >= 120s)",
                first_message_elapsed
            );
            return ContextDecision::ProcessNow {
                reason: format!("Timeout de seguran√ßa ({}s)", first_message_elapsed),
            };
        }

        // Nenhuma regra ativada - aguardar mais mensagens
        tracing::debug!(
            "‚è≥ SmartContextManager: Aguardando mais mensagens ({} msgs, {}s elapsed)",
            message_count,
            last_message_elapsed
        );

        ContextDecision::Wait
    }

    /// Calcula keyword overlap entre primeira e √∫ltima mensagem
    ///
    /// Retorna percentual de palavras-chave em comum (0.0 a 1.0)
    fn calculate_keyword_overlap(contexts: &[MessageContext]) -> Option<f32> {
        if contexts.len() < 2 {
            return None;
        }

        let first_keywords = contexts[0].extract_keywords();
        let last_keywords = contexts.last().unwrap().extract_keywords();

        if first_keywords.is_empty() || last_keywords.is_empty() {
            return Some(0.0);
        }

        let intersection_count = first_keywords.intersection(&last_keywords).count();
        let union_count = first_keywords.union(&last_keywords).count();

        Some(intersection_count as f32 / union_count as f32)
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;

    #[test]
    fn test_closing_message_detection() {
        let payload = json!({ "texto_mensagem": "Muito obrigado, pode fechar!" });
        let context = MessageContext::from_payload(&payload, Instant::now()).unwrap();
        assert!(context.is_closing_message());
    }

    #[test]
    fn test_question_detection() {
        let payload = json!({ "texto_mensagem": "Como fa√ßo para criar uma tarefa?" });
        let context = MessageContext::from_payload(&payload, Instant::now()).unwrap();
        assert!(context.is_question());
    }

    #[test]
    fn test_confirmation_detection() {
        let payload = json!({ "texto_mensagem": "sim" });
        let context = MessageContext::from_payload(&payload, Instant::now()).unwrap();
        assert!(context.is_confirmation());
    }

    #[test]
    fn test_keyword_extraction() {
        let payload = json!({
            "texto_mensagem": "Preciso criar uma tarefa urgente no ClickUp sobre o cliente Nexcode"
        });
        let context = MessageContext::from_payload(&payload, Instant::now()).unwrap();
        let keywords = context.extract_keywords();

        assert!(keywords.contains("preciso"));
        assert!(keywords.contains("criar"));
        assert!(keywords.contains("tarefa"));
        assert!(keywords.contains("urgente"));
    }

    #[test]
    fn test_safety_timeout_8_messages() {
        let messages: Vec<Value> = (0..8)
            .map(|i| json!({ "texto_mensagem": format!("Mensagem {}", i) }))
            .collect();
        let timestamps: Vec<Instant> = (0..8).map(|_| Instant::now()).collect();

        let decision = SmartContextManager::should_process_now(&messages, &timestamps, None);
        assert!(matches!(decision, ContextDecision::ProcessNow { .. }));
    }

    #[test]
    fn test_action_completion_pattern() {
        let now = Instant::now();
        let messages = vec![
            json!({ "texto_mensagem": "Como criar tarefa?" }), // Pergunta
            json!({ "texto_mensagem": "Voc√™ pode criar pela interface" }), // Resposta
            json!({ "texto_mensagem": "ok" }), // Confirma√ß√£o
        ];
        let timestamps = vec![now, now, now];

        let decision = SmartContextManager::should_process_now(&messages, &timestamps, None);
        assert!(matches!(decision, ContextDecision::ProcessNow { .. }));
    }
}
